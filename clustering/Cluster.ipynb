{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../data/features/merged.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset on a year to reduce ovrelap/muddiness\n",
    "data = data[data['YEAR'] == 2018]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We don't want to use beat and year as features\n",
    "# We also don't want district or sector\n",
    "training_data = data.drop(['BEAT','YEAR','ISR_DISTRICT','ISR_SECTOR', 'UOF_DISTRICT'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize columns\n",
    "# This puts all features at same importance. We may want type or shootings to be more important somehow.\n",
    "scaler = StandardScaler()\n",
    "data_scaled = pd.DataFrame(scaler.fit_transform(training_data), columns=training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# Do PCA\n",
    "pca = PCA()\n",
    "pca.fit(data_scaled)\n",
    "data_pc = pd.DataFrame(pca.transform(data_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from sklearn.metrics import calinski_harabasz_score, davies_bouldin_score, silhouette_score\n",
    "def grid_search_clustering(model, param_grid, metric, data):\n",
    "    results = pd.DataFrame(columns=[\"Model\", \"Params\",\"Score\",\"VRScore\",\"DBScore\",\"SilScore\",\"Time\", \"Labels\"])\n",
    "    for params in param_grid: \n",
    "        # Train the clustering model\n",
    "        start = datetime.datetime.now()\n",
    "        print(\"Training model with:\", params)\n",
    "        model.set_params(**params)\n",
    "        labels = model.fit_predict(data)\n",
    "        stop = datetime.datetime.now()\n",
    "        print(\"Training Time Elapsed:\", stop - start)\n",
    "        # Compute user-specified score of the clustering quality\n",
    "        if type(metric) == str:\n",
    "            score = getattr(model, metric)\n",
    "        else:\n",
    "            score = np.nan\n",
    "        # Compute common cluster quality scores\n",
    "        try:\n",
    "            vr_score = calinski_harabasz_score(data, labels)\n",
    "        except:\n",
    "            # returns one cluster\n",
    "            vr_score = np.nan\n",
    "        try:\n",
    "            sil_score = silhouette_score(data, labels)\n",
    "        except:\n",
    "            # returns one cluster\n",
    "            sil_score = np.nan\n",
    "        try:\n",
    "            db_score = davies_bouldin_score(data, labels)\n",
    "        except:\n",
    "            # returns one cluster\n",
    "            db_score = np.nan\n",
    "        # Save results\n",
    "        results = results.append({ \\\n",
    "                        \"Model\": type(model).__name__, \\\n",
    "                        \"Params\":str(params), \\\n",
    "                        \"Score\": score, \\\n",
    "                        \"VRScore\": vr_score, \\\n",
    "                        \"DBScore\": db_score, \\\n",
    "                        \"SilScore\": sil_score, \\\n",
    "                        \"Time\": stop-start, \\\n",
    "                        \"Labels\": labels}, \\\n",
    "                        ignore_index=True)\n",
    "\n",
    "    print(\"Grid search completed.\")\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Training model with: {'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.031085\n",
      "Training model with: {'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.037700\n",
      "Training model with: {'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.040435\n",
      "Training model with: {'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.038790\n",
      "Training model with: {'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.054938\n",
      "Training model with: {'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.066297\n",
      "Grid search completed.\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.008048\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.006639\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.007528\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.007146\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.006350\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'complete', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.007369\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.006968\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.005233\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.005339\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.005430\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.005849\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'average', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.005345\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.005036\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.006183\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.004700\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.005165\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.004220\n",
      "Training model with: {'affinity': 'euclidean', 'linkage': 'single', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.004627\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.006859\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.006756\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.006389\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.005882\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.007538\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'complete', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.007053\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.005274\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.005190\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.005101\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.005297\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.005581\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'average', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.005593\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 2}\n",
      "Training Time Elapsed: 0:00:00.004275\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 3}\n",
      "Training Time Elapsed: 0:00:00.004220\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 4}\n",
      "Training Time Elapsed: 0:00:00.005196\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 5}\n",
      "Training Time Elapsed: 0:00:00.005961\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 7}\n",
      "Training Time Elapsed: 0:00:00.005033\n",
      "Training model with: {'affinity': 'cosine', 'linkage': 'single', 'n_clusters': 9}\n",
      "Training Time Elapsed: 0:00:00.004210\n",
      "Grid search completed.\n",
      "Training model with: {'eps': 0.01, 'metric': 'euclidean', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.005369\n",
      "Training model with: {'eps': 0.01, 'metric': 'euclidean', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.004208\n",
      "Training model with: {'eps': 0.01, 'metric': 'euclidean', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.004530\n",
      "Training model with: {'eps': 0.01, 'metric': 'euclidean', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.004755\n",
      "Training model with: {'eps': 0.01, 'metric': 'cosine', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.005313\n",
      "Training model with: {'eps': 0.01, 'metric': 'cosine', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005316\n",
      "Training model with: {'eps': 0.01, 'metric': 'cosine', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.005619\n",
      "Training model with: {'eps': 0.01, 'metric': 'cosine', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.005507\n",
      "Training model with: {'eps': 0.1, 'metric': 'euclidean', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.004650\n",
      "Training model with: {'eps': 0.1, 'metric': 'euclidean', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005302\n",
      "Training model with: {'eps': 0.1, 'metric': 'euclidean', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.007271\n",
      "Training model with: {'eps': 0.1, 'metric': 'euclidean', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.005453\n",
      "Training model with: {'eps': 0.1, 'metric': 'cosine', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.006008\n",
      "Training model with: {'eps': 0.1, 'metric': 'cosine', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005017\n",
      "Training model with: {'eps': 0.1, 'metric': 'cosine', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.006164\n",
      "Training model with: {'eps': 0.1, 'metric': 'cosine', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.005780\n",
      "Training model with: {'eps': 0.2, 'metric': 'euclidean', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.005320\n",
      "Training model with: {'eps': 0.2, 'metric': 'euclidean', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005947\n",
      "Training model with: {'eps': 0.2, 'metric': 'euclidean', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.004791\n",
      "Training model with: {'eps': 0.2, 'metric': 'euclidean', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.004221\n",
      "Training model with: {'eps': 0.2, 'metric': 'cosine', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.005618\n",
      "Training model with: {'eps': 0.2, 'metric': 'cosine', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005225\n",
      "Training model with: {'eps': 0.2, 'metric': 'cosine', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.006682\n",
      "Training model with: {'eps': 0.2, 'metric': 'cosine', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.004616\n",
      "Training model with: {'eps': 0.5, 'metric': 'euclidean', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.005114\n",
      "Training model with: {'eps': 0.5, 'metric': 'euclidean', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.004998\n",
      "Training model with: {'eps': 0.5, 'metric': 'euclidean', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.004262\n",
      "Training model with: {'eps': 0.5, 'metric': 'euclidean', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.004330\n",
      "Training model with: {'eps': 0.5, 'metric': 'cosine', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.004720\n",
      "Training model with: {'eps': 0.5, 'metric': 'cosine', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005399\n",
      "Training model with: {'eps': 0.5, 'metric': 'cosine', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.004880\n",
      "Training model with: {'eps': 0.5, 'metric': 'cosine', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.005121\n",
      "Training model with: {'eps': 0.9, 'metric': 'euclidean', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.004256\n",
      "Training model with: {'eps': 0.9, 'metric': 'euclidean', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.004284\n",
      "Training model with: {'eps': 0.9, 'metric': 'euclidean', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.004574\n",
      "Training model with: {'eps': 0.9, 'metric': 'euclidean', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.007132\n",
      "Training model with: {'eps': 0.9, 'metric': 'cosine', 'min_samples': 2}\n",
      "Training Time Elapsed: 0:00:00.007363\n",
      "Training model with: {'eps': 0.9, 'metric': 'cosine', 'min_samples': 5}\n",
      "Training Time Elapsed: 0:00:00.005695\n",
      "Training model with: {'eps': 0.9, 'metric': 'cosine', 'min_samples': 10}\n",
      "Training Time Elapsed: 0:00:00.006857\n",
      "Training model with: {'eps': 0.9, 'metric': 'cosine', 'min_samples': 100}\n",
      "Training Time Elapsed: 0:00:00.008550\n",
      "Grid search completed.\n",
      "Training model with: {'n_components': 2, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.019496\n",
      "Training model with: {'n_components': 2, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.145046\n",
      "Training model with: {'n_components': 3, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.022621\n",
      "Training model with: {'n_components': 3, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.177587\n",
      "Training model with: {'n_components': 4, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.038036\n",
      "Training model with: {'n_components': 4, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.275024\n",
      "Training model with: {'n_components': 5, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.043197\n",
      "Training model with: {'n_components': 5, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.327179\n",
      "Training model with: {'n_components': 7, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.055847\n",
      "Training model with: {'n_components': 7, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.345742\n",
      "Training model with: {'n_components': 9, 'n_init': 1}\n",
      "Training Time Elapsed: 0:00:00.083459\n",
      "Training model with: {'n_components': 9, 'n_init': 10}\n",
      "Training Time Elapsed: 0:00:00.564355\n",
      "Grid search completed.\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 2, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:08.217154\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 2, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:08.025900\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 2, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:08.554702\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 2, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:09.037243\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 3, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:01.486843\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 3, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:01.100297\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 3, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:01.368069\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 3, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:01.152470\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 4, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:01.262785\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 4, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:01.169020\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 4, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.958046\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 4, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.934417\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 5, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.748223\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 5, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.717855\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 5, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.698477\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 5, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.701938\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 7, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.480006\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 7, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.459476\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 7, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.436996\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 7, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.515217\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 9, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.207951\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 9, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.258791\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 9, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.212681\n",
      "Training model with: {'affinity': 'rbf', 'n_clusters': 9, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.204857\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 2, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.048090\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 2, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.085947\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 2, 'n_neighbors': 10}\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training Time Elapsed: 0:00:00.072291\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 2, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.085996\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 3, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.062679\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 3, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.059738\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 3, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.123119\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 3, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.096165\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 4, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.088475\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 4, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.073339\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 4, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.088778\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 4, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.098245\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 5, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.089407\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 5, 'n_neighbors': 5}\n",
      "Training Time Elapsed: 0:00:00.068968\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 5, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.088623\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 5, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.107397\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 7, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.097396\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 7, 'n_neighbors': 5}\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training Time Elapsed: 0:00:00.086294\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 7, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.101994\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 7, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.122683\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 9, 'n_neighbors': 2}\n",
      "Training Time Elapsed: 0:00:00.099941\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 9, 'n_neighbors': 5}\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/manifold/_spectral_embedding.py:245: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n",
      "Training Time Elapsed: 0:00:00.095203\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 9, 'n_neighbors': 10}\n",
      "Training Time Elapsed: 0:00:00.102924\n",
      "Training model with: {'affinity': 'nearest_neighbors', 'n_clusters': 9, 'n_neighbors': 100}\n",
      "Training Time Elapsed: 0:00:00.133326\n",
      "Grid search completed.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans, AgglomerativeClustering, DBSCAN, SpectralClustering\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "params_km = {'n_clusters':[2,3,4,5,7,9]}\n",
    "km_result = grid_search_clustering(KMeans(), ParameterGrid(params_km), 'inertia_', data_scaled)        \n",
    "\n",
    "params_hagg = {'n_clusters':[2,3,4,5,7,9], 'affinity':['euclidean','cosine'], 'linkage':['complete','average','single']}\n",
    "hagg_result = grid_search_clustering(AgglomerativeClustering(), ParameterGrid(params_hagg), None, data_scaled)        \n",
    "\n",
    "params_dbscan = {'eps':[.01,.1,.2,.5,.9], 'min_samples':[2, 5, 10, 100], 'metric':['euclidean','cosine']}\n",
    "dbscan_result = grid_search_clustering(DBSCAN(), ParameterGrid(params_dbscan), None, data_scaled)        \n",
    "\n",
    "params_gauss = {'n_components':[2,3,4,5,7,9], 'n_init':[1,10]}\n",
    "gauss_result = grid_search_clustering(GaussianMixture(), ParameterGrid(params_gauss), 'lower_bound_', data_scaled)        \n",
    "\n",
    "params_spectral = {'n_clusters':[2,3,4,5,7,9], 'affinity':['rbf','nearest_neighbors'], 'n_neighbors':[2, 5, 10, 100]}\n",
    "spectral_result = grid_search_clustering(SpectralClustering(), ParameterGrid(params_spectral), None, data_scaled)        \n",
    "\n",
    "results = pd.concat([km_result, hagg_result, dbscan_result, gauss_result, spectral_result])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply learned labels to data frame\n",
    "best_labels_km = km_result.sort_values(by='Score', ascending=False).head(1)['Labels'].to_numpy()[0]\n",
    "best_labels_gauss = gauss_result.sort_values(by='Score', ascending=False).head(1)['Labels'].to_numpy()[0]\n",
    "best_labels_dbscore = results.sort_values(by='DBScore', ascending=True).head(1)['Labels'].to_numpy()[0]\n",
    "best_labels_vrscore = results.sort_values(by='VRScore', ascending=True).head(1)['Labels'].to_numpy()[0]\n",
    "best_labels_silscore = results.sort_values(by='SilScore', ascending=False).head(1)['Labels'].to_numpy()[0]\n",
    "clustered = pd.concat([data, \\\n",
    "                        pd.Series(best_labels_km, name='KMeans'), \\\n",
    "                        pd.Series(best_labels_gauss, name='Gauss'), \\\n",
    "                        pd.Series(best_labels_dbscore, name='Davies'), \\\n",
    "                        pd.Series(best_labels_vrscore, name='VarRatio'), \\\n",
    "                        pd.Series(best_labels_silscore, name='Silo'), \\\n",
    "                        ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hack for importing sibling modules\n",
    "### SNIPPET ATTRIBUTION: https://izziswift.com/import-local-function-from-a-module-housed-in-another-directory-with-relative-imports-in-jupyter-notebook-using-python-3/\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "### END SNIPPET "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util.cat_reshaper import listcolumn_pivot_longer\n",
    "\n",
    "pie_plt_data = pd.concat([clustered['BEAT'], pd.get_dummies(clustered['KMeans'], prefix='Cluster')], axis=1).groupby(by='BEAT').agg('sum')\n",
    "pie_plt_data.columns\n",
    "\n",
    "tmp = listcolumn_pivot_longer(pie_plt_data, 'Cluster', 'Cluster_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "           Cluster\n",
       "BEAT              \n",
       "111.0        [0.0]\n",
       "112.0        [0.0]\n",
       "113.0   [0.0, 1.0]\n",
       "114.0        [0.0]\n",
       "121.0        [0.0]\n",
       "...            ...\n",
       "2531.0          []\n",
       "2532.0          []\n",
       "2533.0          []\n",
       "2534.0          []\n",
       "2535.0          []\n",
       "\n",
       "[236 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Cluster</th>\n    </tr>\n    <tr>\n      <th>BEAT</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>111.0</th>\n      <td>[0.0]</td>\n    </tr>\n    <tr>\n      <th>112.0</th>\n      <td>[0.0]</td>\n    </tr>\n    <tr>\n      <th>113.0</th>\n      <td>[0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>114.0</th>\n      <td>[0.0]</td>\n    </tr>\n    <tr>\n      <th>121.0</th>\n      <td>[0.0]</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2531.0</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2532.0</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2533.0</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2534.0</th>\n      <td>[]</td>\n    </tr>\n    <tr>\n      <th>2535.0</th>\n      <td>[]</td>\n    </tr>\n  </tbody>\n</table>\n<p>236 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 227
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpp_venv",
   "language": "python",
   "name": "mlpp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}