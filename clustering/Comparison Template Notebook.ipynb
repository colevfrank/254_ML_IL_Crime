{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "conda_mlpp",
   "display_name": "Python 3.9.4 64-bit (conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "661842a713784b077722e898fc714d7d7522e83960fa708323e6148162ebf3b9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Clustering Comparison Analysis\n",
    "\n",
    "We run a clustering model on some subset of the data and measure the similarity of the produced clusterings."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import geopandas as gp\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in data\n",
    "data = pd.read_csv('../data/features/merged.csv')"
   ]
  },
  {
   "source": [
    "## Create training data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here on out, we'll use a separate variable \"training_data\" for filtered data. \n",
    "# It's good not to overwrite the original 'data' variable\n",
    "# in case we want to recover the filtered columns later.\n",
    "training_data = data.copy()"
   ]
  },
  {
   "source": [
    "### ... by filtering columns"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ REPLACE THIS CODE TO DROP COLUMNS IF NECESSARY ]\n",
    "\n",
    "# demo_columns = ['COMPLAINTS_BLACK','COMPLAINTS_HISPANIC','COMPLAINTS_WHITE','ISR_BLACK','ISR_WHITE','ISR_HISPANIC','UOF_HISPANIC','UOF_BLACK','UOF_WHITE','CENSUS_WHITE','CENSUS_BLACK','CENSUS_HISPANIC','CENSUS_MEDIAN INCOME', 'CENSUS_TOTAL POP']\n",
    "# training_data = training_data.drop(demo_columns, axis=1)"
   ]
  },
  {
   "source": [
    "### .. by aggregating rows\n",
    "\n",
    "For model selection, since we're eventually clustering by beat, we'll aggregate by summing all years together.\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ REPLACE THIS CODE TO DROP ROWS IF NECESSARY ]\n",
    "\n",
    "# training_data = training_data.drop('YEAR',axis=1).groupby(by='BEAT').agg(np.sum).reset_index(drop=True)"
   ]
  },
  {
   "source": [
    "## Preprocess / Transform Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "# Normalize columns\n",
    "scaler = StandardScaler()\n",
    "scaled_training_data = pd.DataFrame(scaler.fit_transform(training_data),\\\n",
    "    columns=training_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do PCA\n",
    "from util_clustering import generate_pca_data\n",
    "N_TOP_PCA_COMPONENTS = 6 # See Model Selection.ipynb for why we chose this number.\n",
    "pca_training_data, pca = generate_pca_data(scaled_training_data, N_TOP_PCA_COMPONENTS)"
   ]
  },
  {
   "source": [
    "## Setup Best Model & Hyperparameters"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "KMeans(n_clusters=7)"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "PARAM_N_CLUSTERS = 7 # See Model Selection.ipynb for why we chose this number.\n",
    "cluster_model_params = {'n_clusters':PARAM_N_CLUSTERS}\n",
    "cluster_model = KMeans()\n",
    "cluster_model.set_params(**cluster_model_params)"
   ]
  },
  {
   "source": [
    "## Run the model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_labels = cluster_model.fit_predict(pca_training_data)\n",
    "clustered_data = pd.concat([pca_training_data, pd.Series(cluster_labels, name='Cluster')], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "        PC1       PC2       PC3       PC4       PC5       PC6  Cluster\n",
       "0  2.154153 -0.556139  1.204775 -1.169982  2.916138 -0.345154        2\n",
       "1 -0.712959 -0.397213  0.825376 -0.792141  2.122832 -0.394202        1\n",
       "2 -0.662858 -0.397982  0.398048  0.343189  1.169731 -0.530594        1\n",
       "3 -0.783367 -0.285063  0.855373  0.000778  1.045543 -0.769667        1\n",
       "4 -2.824287  0.650939  0.038874  0.125945  0.573302 -0.183643        3"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>PC1</th>\n      <th>PC2</th>\n      <th>PC3</th>\n      <th>PC4</th>\n      <th>PC5</th>\n      <th>PC6</th>\n      <th>Cluster</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2.154153</td>\n      <td>-0.556139</td>\n      <td>1.204775</td>\n      <td>-1.169982</td>\n      <td>2.916138</td>\n      <td>-0.345154</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>-0.712959</td>\n      <td>-0.397213</td>\n      <td>0.825376</td>\n      <td>-0.792141</td>\n      <td>2.122832</td>\n      <td>-0.394202</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>-0.662858</td>\n      <td>-0.397982</td>\n      <td>0.398048</td>\n      <td>0.343189</td>\n      <td>1.169731</td>\n      <td>-0.530594</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>-0.783367</td>\n      <td>-0.285063</td>\n      <td>0.855373</td>\n      <td>0.000778</td>\n      <td>1.045543</td>\n      <td>-0.769667</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>-2.824287</td>\n      <td>0.650939</td>\n      <td>0.038874</td>\n      <td>0.125945</td>\n      <td>0.573302</td>\n      <td>-0.183643</td>\n      <td>3</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": [
    "clustered_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}