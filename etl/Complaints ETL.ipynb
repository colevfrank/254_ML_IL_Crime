{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Complainants / Subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load \"by complaintant\" dataset\n",
    "comdata = pd.read_csv(\"../data/raw/Complaints/COPA_Cases_-_By_Complainant_or_Subject.csv\", \\\n",
    "                   dtype={\"LOG_NO\":str,\"CASE_TYPE\":str}) \\\n",
    "        .assign(DATETIME = lambda x: pd.to_datetime(x.COMPLAINT_DATE, format = \"%m/%d/%Y %H:%M:%S %p\")) \\\n",
    "        .assign(COMPLAINT_YEAR = lambda x: x.DATETIME.dt.year)\n",
    "comdata['LOG_NO'] = comdata['LOG_NO'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX:  # Commented out because these may be multi-party complaints\n",
    "# Discard literal duplicates\n",
    "# comdata.drop_duplicates(inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all time columns except year, which is needed for aggregation\n",
    "comdata.drop(labels=['COMPLAINT_DATE', 'COMPLAINT_HOUR', \\\n",
    "                     'COMPLAINT_DAY', 'COMPLAINT_MONTH', 'DATETIME'], \\\n",
    "             axis='columns', \\\n",
    "            inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The question of which cases move through the system and how quickly is interesting, \n",
    "# but since we got rid of the \"time\" axis, its easier to assume all cases are \"Closed\" for now\n",
    "comdata.drop(labels='CURRENT_STATUS', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similar reasons, let's drop assignment until we read up on who sees which kind of cases\n",
    "comdata.drop(labels='ASSIGNMENT', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For similar reasons, let's drop case_type until we decide we want to include these procedural details\n",
    "comdata.drop(labels='CASE_TYPE', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Commented out because I think the 'duplicated' records actually refer to a party of complaintants\n",
    "\n",
    "# Clean up duplicates\n",
    "# logcounts = comdata['LOG_NO'].value_counts()\n",
    "# duplogs = logcounts[logcounts > 1].index\n",
    "\n",
    "# def clean_updated_unknowns(data, column_name, dups):\n",
    "#     is_unknown = data[column_name] == 'Unknown'\n",
    "#     is_dup = data['LOG_NO'].isin(dups)\n",
    "#     return data[~(is_unknown & is_dup)]\n",
    "\n",
    "# for col in comdata.columns:\n",
    "#     comdata = clean_updated_unknowns(comdata, col, duplogs)\n",
    "    \n",
    "# Clean up duplicates\n",
    "# logcounts = comdata['LOG_NO'].value_counts()\n",
    "# duplogs = logcounts[logcounts > 1].index\n",
    "# comdata[comdata['LOG_NO'] == duplogs[45]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new indicator columns for the multi-categorical columns\n",
    "\n",
    "def listcolumn_pivot_wider(data, column_name, prefix):\n",
    "    '''\n",
    "    Split a pipe-separated multi-valued string column into dummy variables. \n",
    "    Append dummies to tbl and remove original column.\n",
    "    '''\n",
    "    cleaned = data[column_name].str.replace(\" \", \"\", regex=False)\n",
    "    dummies = cleaned.str.get_dummies()\n",
    "    dummies.rename(columns=lambda c: prefix + c, inplace=True)\n",
    "    data.drop(labels=column_name, axis='columns', inplace=True)\n",
    "    return pd.concat([data, dummies], axis=1)\n",
    "\n",
    "comdata = listcolumn_pivot_wider(comdata, 'CURRENT_CATEGORY', 'COMPLAINT_CAT_')\n",
    "comdata = listcolumn_pivot_wider(comdata, 'FINDING_CODE', 'COMPLAINT_FINDING_')\n",
    "comdata = listcolumn_pivot_wider(comdata, 'RACE_OF_COMPLAINANT', 'COMPLAINANT_RACE_')\n",
    "comdata = listcolumn_pivot_wider(comdata, 'SEX_OF_COMPLAINANT', 'COMPLAINANT_SEX_')\n",
    "comdata = listcolumn_pivot_wider(comdata, 'AGE_OF_COMPLAINANT', 'COMPLAINANT_AGE_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-252-ee3aa78e18bb>:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  comdata = comdata.assign(BEAT = comdata['BEAT'].str.replace(\"\\s*\", \"\")) \\\n"
     ]
    }
   ],
   "source": [
    "# Pivot \"beats\" column longer: create more rows when complaint spans beats\n",
    "comdata = comdata.assign(BEAT = comdata['BEAT'].str.replace(\"\\s*\", \"\", regex=True)) \\\n",
    "                 .assign(BEAT = comdata['BEAT'].str.split(\"|\")) \\\n",
    "                 .explode('BEAT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform Police Shooting to numeric\n",
    "comdata = comdata.assign(POLICE_SHOOTING = lambda x: x.POLICE_SHOOTING.map({'No':0.0, 'Yes':1.0}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate\n",
    "comdata_agg = comdata.drop(labels='LOG_NO', axis='columns').groupby(by=['BEAT','COMPLAINT_YEAR']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to disk\n",
    "!mkdir -p ../data/processed\n",
    "comdata_agg.to_csv(\"../data/processed/complaints.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Officers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eric/Library/Python/3.9/lib/python/site-packages/IPython/core/interactiveshell.py:3165: DtypeWarning: Columns (4,5,6,7,8,9,10,11,12) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n"
     ]
    }
   ],
   "source": [
    "# Load \"by officer\" dataset\n",
    "offdata = pd.read_csv(\"../data/raw/Complaints/COPA_Cases_-_By_Involved_Officer.csv\", \\\n",
    "                      dtype={\"LOG_NO\":str, \"CASE_TYPE\":str}) \\\n",
    "            .assign(DATETIME = lambda x: pd.to_datetime(x.COMPLAINT_DATE, format = \"%m/%d/%Y %H:%M:%S %p\")) \\\n",
    "            .assign(COMPLAINT_YEAR = lambda x: x.DATETIME.dt.year)\n",
    "offdata['LOG_NO'] = offdata['LOG_NO'].astype(str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XXX: Commented out because these may be multi-party complaints\n",
    "# Drop literal duplicates\n",
    "# offdata.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop all time columns except year, which is needed for aggregation\n",
    "offdata.drop(labels=['COMPLAINT_DATE', 'COMPLAINT_HOUR', \\\n",
    "                     'COMPLAINT_DAY', 'COMPLAINT_MONTH', 'DATETIME'], \\\n",
    "             axis='columns', \\\n",
    "            inplace = True)\n",
    "\n",
    "# The question of which cases move through the system and how quickly is interesting, \n",
    "# but since we got rid of the \"time\" axis, its easier to assume all cases are \"Closed\" for now\n",
    "offdata.drop(labels='CURRENT_STATUS', axis='columns', inplace=True)\n",
    "\n",
    "# For similar reasons, let's drop assignment until we read up on who sees which kind of cases\n",
    "offdata.drop(labels='ASSIGNMENT', axis='columns', inplace=True)\n",
    "\n",
    "# For similar reasons, let's drop case_type until we decide we want to include these procedural details\n",
    "offdata.drop(labels='CASE_TYPE', axis='columns', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: merge into by-complainant"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlpp_venv",
   "language": "python",
   "name": "mlpp_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
